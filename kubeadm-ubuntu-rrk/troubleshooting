application failure
====================

labels not matched between pod and service

 you inspect the mysql-service, you will see that that the selector used does not match the label on the mysql pod.
 
 kubectl -n gamma describe svc mysql-service | grep -i selector
 
 kubectl -n gamma describe pod mysql | grep -i label  
 
 As you can see the selector used is name=sql001 whereas it should be name=mysql.
Update the mysql-service to use the correct selector as per the below YAML
 
 apiVersion: v1
kind: Service
metadata:
  name: mysql-service
  namespace: gamma
spec:
    ports:
    - port: 3306
      targetPort: 3306
    selector:
      name: mysql
      
      
      ======================
      
      error: 502 Bad Gateway
   Try accessing the web application from the browser using the tab called app. You will notice that it cannot connect to the MySQL database:
   
   from browser error : Environment Variables: DB_Host=mysql-service; DB_Database=Not Set; DB_User=sql-user; DB_Password=paswrd; 1045 (28000): Access denied for user 'sql-user'@'10.244.1.9' (using password: YES)
   
   According to the architecture diagram, the DB_User should be root but it is set to sql-user in the webapp-mysql deployment.
   
   
   =================================================
   
   error : Environment Variables: DB_Host=mysql-service; DB_Database=Not Set; DB_User=root; DB_Password=paswrd; 2003: Can't connect to MySQL server on 'mysql-service:3306' (-2 Name does not resolve) 
   
   The service name used for the MySQL Pod is incorrect. According to the Architecture diagram, it should be mysql-service.
To fix this, first delete the current service: kubectl -n alpha delete svc mysql
Then create a new service with the following YAML file (or use imperative command):

apiVersion: v1
kind: Service
metadata:
  name: mysql-service
  namespace: alpha
spec:
    ports:
    - port: 3306
      targetPort: 3306
    selector:
      name: mysql

Use the command kubectl -n delta edit deployments.apps webapp-mysql and update the environment variable as follows

====================================================

error in browser:  Environment Variables: DB_Host=mysql-service; DB_Database=Not Set; DB_User=sql-user; DB_Password=paswrd; 1045 (28000): Access denied for user 'sql-user'@'10.42.0.18' (using password: YES) 

If you inspect the environment variable called MYSQL_ROOT_PASSWORD, you will notice that the value is incorrect as compared to the architecture diagram:

 kubectl -n epsilon describe pod mysql  | grep MYSQL_ROOT_PASSWORD
 
 Correct this by deleting and recreating the mysql pod with the correct environment variable as follows:
 
 spec:
  containers:
  - env:
    - name: MYSQL_ROOT_PASSWORD
      value: paswrd
      
      ===============
      
      Also edit the webapp-mysql deployment and make sure that the DB_User environment variable is set to root as follows:
      
      pec:
      containers:
      - env:
        - name: DB_Host
          value: mysql-service
        - name: DB_User
          value: root
        - name: DB_Password
          value: paswrd
          
          ====================================
          
          If you inspect the web-service, you will see that the nodePort used is incorrect.
This service should be exposed on port 30081 and NOT 30088

svc web-service 
NAME          TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
web-service   NodePort   10.102.190.212   <none>        8080:30088/TCP   3m1s
root@controlplane:~#


To correct this, delete the service and recreate it using the below YAML file:

```
apiVersion: v1
kind: Service
metadata:
  name: web-service
  namespace: zeta
spec:
  ports:
  - nodePort: 30081
    port: 8080
    targetPort: 8080
  selector:
    name: webapp-mysql
  type: NodePort


2. Also edit the webapp-mysql deployment and make sure that the DB_User environment variable is set to root as follows:

spec:
      containers:
      - env:
        - name: DB_Host
          value: mysql-service
        - name: DB_User
          value: root
        - name: DB_Password
          value: paswrd


3. The DB_Password used by the mysql pod is incorrect. Delete the current pod and recreate with the correct environment variable as per the snippet below:

spec:
  containers:
  - env:
    - name: MYSQL_ROOT_PASSWORD
      value: paswrd

Once the objects are recreated, and you should be able to access the application.

==========================================================================================

error :  Environment Variables: DB_Host=mysql-service; DB_Database=Not Set; DB_User=root; DB_Password=paswrd; 2003: Can't connect to MySQL server on 'mysql-service:3306' (111 Connection refused) 

If you inspect the mysql-service in the beta namespace, you will notice that the targetPort used to create this service is incorrect.
Compare this to the Architecture diagram and change it to 3306. Update the mysql-service as per the below YAML:

apiVersion: v1
kind: Service
metadata:
  name: mysql-service
  namespace: beta
spec:
    ports:
    - port: 3306
      targetPort: 3306
    selector:
      name: mysql


=====================================
=====================================

ControlPlane Failure:

he cluster is broken. We tried deploying an application but it's not working. Troubleshoot and fix the issue.

Start looking at the deployments.

Run the command: kubectl get pods -n kube-system. Check the kube-scheduler manifest file and fix the issue.
The command run by the scheduler pod is incorrect. Here is a snippet of the YAML file.

spec:
  containers:
  - command:
    - kube-scheduler
    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --leader-elect=true
    - --port=0

Once this is corrected, the scheduler pod will be recreated.

=======================

Scale the deployment app to 2 pods.

kubectl scale deploy app --replicas=2

================

even though the deployment was scaled to 2, the number of PODs does not seem to increase. Investigate and fix the issue.

Inspect the component responsible for managing deployments and replicasets.

Run the command: kubectl get po -n kube-system and check the logs of kube-controller-manager pod to know the failure reason by running command: kubectl logs -n kube-system kube-controller-manager-controlplane
Then check the kube-controller-manager configuration file at /etc/kubernetes/manifests/kube-controller-manager.yaml and fix the issue.

root@controlplane:/etc/kubernetes/manifests# kubectl -n kube-system logs kube-controller-manager-controlplane
Flag --port has been deprecated, see --secure-port instead.
I0725 07:25:16.842138       1 serving.go:331] Generated self-signed cert in-memory
stat /etc/kubernetes/controller-manager-XXXX.conf: no such file or directory
root@controlplane:/etc/kubernetes/manifests# 

The configuration file specified (/etc/kubernetes/controller-manager-XXXX.conf) does not exist.
Correct the path: 

/etc/kubernetes/controller-manager.conf

============================================================

Something is wrong with scaling again. We just tried scaling the deployment to 3 replicas. But it's not happening.

Investigate and fix the issue.

Check the volume mount path in kube-controller-manager manifest file at /etc/kubernetes/manifests.
Just as we did in the previous question, inspect the logs of the kube-controller-managerpod:

root@controlplane:/etc/kubernetes/manifests# kubectl -n kube-system logs kube-controller-manager-controlplane
Flag --port has been deprecated, see --secure-port instead.
I0725 07:29:06.155330       1 serving.go:331] Generated self-signed cert in-memory
unable to load client CA file "/etc/kubernetes/pki/ca.crt": open /etc/kubernetes/pki/ca.crt: no such file or directory
root@controlplane:/etc/kubernetes/manifests# 

It appears the path /etc/kubernetes/pki is not mounted from the controlplane to the kube-controller-manager pod. If we inspect the pod manifest file, we can see that the incorrect hostPath is used for the volume:
WRONG

- hostPath:
      path: /etc/kubernetes/WRONG-PKI-DIRECTORY
      type: DirectoryOrCreate


CORRECT: ``yaml

    hostPath: path: /etc/kubernetes/pki type: DirectoryOrCreate ``` Once the path is corrected, the pod will be recreated and our deployment should eventually scale up to 3 replicas.
=============================
==============================

Network Troubleshooting

Network Plugin in kubernetes

--------------------

Kubernetes uses CNI plugins to setup network. The kubelet is responsible for executing plugins as we mention the following parameters in kubelet configuration.

- cni-bin-dir:   Kubelet probes this directory for plugins on startup

- network-plugin: The network plugin to use from cni-bin-dir. It must match the name reported by a plugin probed from the plugin directory.


There are several plugins available and these are some.


1. Weave Net:


  These is the only plugin mentioned in the kubernetes documentation. To install,

kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"


You can find this in following documentation :

              https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/


2. Flannel :


   To install,

  kubectl apply -f   https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml

   

Note: As of now flannel does not support kubernetes network policies.


3. Calico :

   

   To install,

   curl https://docs.projectcalico.org/manifests/calico.yaml -O

  Apply the manifest using the following command.

      kubectl apply -f calico.yaml

   Calico is said to have most advanced cni network plugin.


In CKA and CKAD exam, you won't be asked to install the cni plugin. But if asked you will be provided with the exact url to install it. If not, you can install weave net from the documentation 

      https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/


Note: If there are multiple CNI configuration files in the directory, the kubelet uses the configuration file that comes first by name in lexicographic order.



DNS in Kubernetes
-----------------

Kubernetes uses CoreDNS. CoreDNS is a flexible, extensible DNS server that can serve as the Kubernetes cluster DNS.


Memory and Pods

In large scale Kubernetes clusters, CoreDNS's memory usage is predominantly affected by the number of Pods and Services in the cluster. Other factors include the size of the filled DNS answer cache, and the rate of queries received (QPS) per CoreDNS instance.


Kubernetes resources for coreDNS are:   

    a service account named coredns,

    cluster-roles named coredns and kube-dns

    clusterrolebindings named coredns and kube-dns, 

    a deployment named coredns,

    a configmap named coredns and a

    service named kube-dns.


While analyzing the coreDNS deployment you can see that the the Corefile plugin consists of important configuration which is defined as a configmap.


Port 53 is used for for DNS resolution.


        kubernetes cluster.local in-addr.arpa ip6.arpa {
           pods insecure
           fallthrough in-addr.arpa ip6.arpa
           ttl 30
        }


This is the backend to k8s for cluster.local and reverse domains.


proxy . /etc/resolv.conf


Forward out of cluster domains directly to right authoritative DNS server.



Troubleshooting issues related to coreDNS

1. If you find CoreDNS pods in pending state first check network plugin is installed.

2. coredns pods have CrashLoopBackOff or Error state

If you have nodes that are running SELinux with an older version of Docker you might experience a scenario where the coredns pods are not starting. To solve that you can try one of the following options:

a)Upgrade to a newer version of Docker.

b)Disable SELinux.

c)Modify the coredns deployment to set allowPrivilegeEscalation to true:


    kubectl -n kube-system get deployment coredns -o yaml | \
      sed 's/allowPrivilegeEscalation: false/allowPrivilegeEscalation: true/g' | \
      kubectl apply -f -

d)Another cause for CoreDNS to have CrashLoopBackOff is when a CoreDNS Pod deployed in Kubernetes detects a loop.


  There are many ways to work around this issue, some are listed here:


    Add the following to your kubelet config yaml: resolvConf: <path-to-your-real-resolv-conf-file> This flag tells kubelet to pass an alternate resolv.conf to Pods. For systems using systemd-resolved, /run/systemd/resolve/resolv.conf is typically the location of the "real" resolv.conf, although this can be different depending on your distribution.

    Disable the local DNS cache on host nodes, and restore /etc/resolv.conf to the original.

    A quick fix is to edit your Corefile, replacing forward . /etc/resolv.conf with the IP address of your upstream DNS, for example forward . 8.8.8.8. But this only fixes the issue for CoreDNS, kubelet will continue to forward the invalid resolv.conf to all default dnsPolicy Pods, leaving them unable to resolve DNS.


3. If CoreDNS pods and the kube-dns service is working fine, check the kube-dns service has valid endpoints.

              kubectl -n kube-system get ep kube-dns

If there are no endpoints for the service, inspect the service and make sure it uses the correct selectors and ports.



Kube-Proxy
---------

kube-proxy is a network proxy that runs on each node in the cluster. kube-proxy maintains network rules on nodes. These network rules allow network communication to the Pods from network sessions inside or outside of the cluster.


In a cluster configured with kubeadm, you can find kube-proxy as a daemonset.


kubeproxy is responsible for watching services and endpoint associated with each service. When the client is going to connect to the service using the virtual IP the kubeproxy is responsible for sending traffic to actual pods.


If you run a kubectl describe ds kube-proxy -n kube-system you can see that the kube-proxy binary runs with following command inside the kube-proxy container.


        Command:
          /usr/local/bin/kube-proxy
          --config=/var/lib/kube-proxy/config.conf
          --hostname-override=$(NODE_NAME)

 

    So it fetches the configuration from a configuration file ie, /var/lib/kube-proxy/config.conf and we can override the hostname with the node name of at which the pod is running.

 

  In the config file we define the clusterCIDR, kubeproxy mode, ipvs, iptables, bindaddress, kube-config etc.

 
Troubleshooting issues related to kube-proxy

1. Check kube-proxy pod in the kube-system namespace is running.

2. Check kube-proxy logs.

3. Check configmap is correctly defined and the config file for running kube-proxy binary is correct.

4. kube-config is defined in the config map.

5. check kube-proxy is running inside the container

    # netstat -plan | grep kube-proxy
    tcp        0      0 0.0.0.0:30081           0.0.0.0:*               LISTEN      1/kube-proxy
    tcp        0      0 127.0.0.1:10249         0.0.0.0:*               LISTEN      1/kube-proxy
    tcp        0      0 172.17.0.12:33706       172.17.0.12:6443        ESTABLISHED 1/kube-proxy
    tcp6       0      0 :::10256                :::*                    LISTEN      1/kube-proxy



References:

Debug Service issues:

                     https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/

DNS Troubleshooting:

                     https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/
